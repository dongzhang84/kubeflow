{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction from:\n",
    "\n",
    "https://www.katacoda.com/orm-chris-fregly/scenarios/01_kubeflow_install\n",
    "\n",
    "\n",
    "# Background\n",
    "Deep learning has shown that being able to train large models on vasts amount of data can drastically improve model performance. \n",
    "\n",
    "\n",
    "However, consider the problem of training a deep network with millions, or even billions of parameters. How do we achieve this without waiting for days, or even multiple weeks? Dean et al propose a different training paradigm which allows us to train and serve a model on multiple physical machines. The auth|ors propose two novel methodologies to accomplish this, namely, `model parallelism` and `data parallelism`.\n",
    "\n",
    "\n",
    "## Model Parallelism\n",
    "When a big model can not fit into a single node's memory, model parallel training can be employed to handle the big model. Model parallelism training has two key features:\n",
    "1. Each worker task is responsible for estimating different part of the model parameters. So the computation logic in each worker is different from other one else.\n",
    "2. There is application-level data communication between workers. \n",
    "\n",
    "![Model Parallelism](./img/model_parallelism.jpg)\n",
    "\n",
    "\n",
    "## Data Parallelism\n",
    "\n",
    "The algorithm distributes the data between various tasks.\n",
    "1. Each worker task is responsible for estimating different part of the dataset\n",
    "2. Tasks then exchange their estimate(s) with each other to come up with the right estimate for the step.\n",
    "\n",
    "![Data Parallelism](./img/data_parallelism.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Training in Tensorflow \n",
    "\"Data Parallelism\" is the most common training configuration, it involves multiple tasks in a `worker` job training the same model on different mini-batches of data, updating shared parameters hosted in one or more tasks in a `ps` (parameter server) job. All tasks typically run on different machines or containers. There are many ways to specify this structure in TensorFlow, and Tensorflow team are building libraries that will simplify the work of specifying a replicated model. Other platforms like `MXnet`, `Petuum` also have the same abstraction. \n",
    "\n",
    "- __In-graph replication__. In this approach, the client builds a single tf.Graph that contains one set of parameters (in tf.Variable nodes pinned to /job:ps); and multiple copies of the compute-intensive part of the model, each pinned to a different task in /job:worker.\n",
    "\n",
    "- __Between-graph replication__. In this approach, there is a separate client for each /job:worker task, typically in the same process as the worker task. Each client builds a similar graph containing the parameters (pinned to /job:ps as before using tf.train.replica_device_setter to map them deterministically to the same tasks); and a single copy of the compute-intensive part of the model, pinned to the local task in /job:worker.\n",
    "\n",
    "- __Asynchronous training__. In this approach, each replica of the graph has an independent training loop that executes without coordination. It is compatible with both forms of replication above.\n",
    "\n",
    "- __Synchronous training__. In this approach, all of the replicas read the same values for the current parameters, compute gradients in parallel, and then apply them together. It is compatible with in-graph replication (e.g. using gradient averaging as in the CIFAR-10 multi-GPU trainer), and between-graph replication (e.g. using the tf.train.SyncReplicasOptimizer).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "We will introduce two frameworks in the distributed training. Tensorflow and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Tensorflow PS Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: \"kubeflow.org/v1\"\r\n",
      "kind: \"TFJob\"\r\n",
      "metadata:\r\n",
      "  name: \"distributed-tensorflow-job\"\r\n",
      "spec:\r\n",
      "  tfReplicaSpecs:\r\n",
      "    PS:\r\n",
      "      replicas: 1 \r\n",
      "      restartPolicy: Never\r\n",
      "      template:\r\n",
      "        metadata:\r\n",
      "          annotations:\r\n",
      "            sidecar.istio.io/inject: \"false\"\r\n",
      "        spec:\r\n",
      "          containers:\r\n",
      "            - name: tensorflow\r\n",
      "              image: gcr.io/kubeflow-ci/tf-dist-mnist-test:1.0\r\n",
      "    Worker:\r\n",
      "      replicas: 2 \r\n",
      "      restartPolicy: Never\r\n",
      "      template:\r\n",
      "        metadata:\r\n",
      "          annotations:\r\n",
      "            sidecar.istio.io/inject: \"false\"\r\n",
      "        spec:\r\n",
      "          containers:\r\n",
      "            - name: tensorflow\r\n",
      "              image: gcr.io/kubeflow-ci/tf-dist-mnist-test:1.0\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./distributed-training-jobs/distributed-tensorflow-job.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit TFJob distributed training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfjob.kubeflow.org/distributed-tensorflow-job created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f distributed-training-jobs/distributed-tensorflow-job.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all TFJobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                         STATE     AGE\r\n",
      "distributed-tensorflow-job   Created   33s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get tfjob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check TFJob Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         distributed-tensorflow-job\n",
      "Namespace:    anonymous\n",
      "Labels:       <none>\n",
      "Annotations:  <none>\n",
      "API Version:  kubeflow.org/v1\n",
      "Kind:         TFJob\n",
      "Metadata:\n",
      "  Creation Timestamp:  2020-05-09T01:47:33Z\n",
      "  Generation:          1\n",
      "  Resource Version:    7391\n",
      "  Self Link:           /apis/kubeflow.org/v1/namespaces/anonymous/tfjobs/distributed-tensorflow-job\n",
      "  UID:                 0d23c537-9197-11ea-a820-0242ac110012\n",
      "Spec:\n",
      "  Tf Replica Specs:\n",
      "    PS:\n",
      "      Replicas:        1\n",
      "      Restart Policy:  Never\n",
      "      Template:\n",
      "        Metadata:\n",
      "          Annotations:\n",
      "            sidecar.istio.io/inject:  false\n",
      "        Spec:\n",
      "          Containers:\n",
      "            Image:  gcr.io/kubeflow-ci/tf-dist-mnist-test:1.0\n",
      "            Name:   tensorflow\n",
      "    Worker:\n",
      "      Replicas:        2\n",
      "      Restart Policy:  Never\n",
      "      Template:\n",
      "        Metadata:\n",
      "          Annotations:\n",
      "            sidecar.istio.io/inject:  false\n",
      "        Spec:\n",
      "          Containers:\n",
      "            Image:  gcr.io/kubeflow-ci/tf-dist-mnist-test:1.0\n",
      "            Name:   tensorflow\n",
      "Status:\n",
      "  Conditions:\n",
      "    Last Transition Time:  2020-05-09T01:47:33Z\n",
      "    Last Update Time:      2020-05-09T01:47:33Z\n",
      "    Message:               TFJob distributed-tensorflow-job is created.\n",
      "    Reason:                TFJobCreated\n",
      "    Status:                True\n",
      "    Type:                  Created\n",
      "  Replica Statuses:\n",
      "    PS:\n",
      "    Worker:\n",
      "  Start Time:  2020-05-09T01:47:34Z\n",
      "Events:\n",
      "  Type    Reason                   Age   From         Message\n",
      "  ----    ------                   ----  ----         -------\n",
      "  Normal  SuccessfulCreatePod      59s   tf-operator  Created pod: distributed-tensorflow-job-ps-0\n",
      "  Normal  SuccessfulCreateService  59s   tf-operator  Created service: distributed-tensorflow-job-ps-0\n",
      "  Normal  SuccessfulCreatePod      59s   tf-operator  Created pod: distributed-tensorflow-job-worker-0\n",
      "  Normal  SuccessfulCreatePod      58s   tf-operator  Created pod: distributed-tensorflow-job-worker-1\n",
      "  Normal  SuccessfulCreateService  58s   tf-operator  Created service: distributed-tensorflow-job-worker-0\n",
      "  Normal  SuccessfulCreateService  58s   tf-operator  Created service: distributed-tensorflow-job-worker-1\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe tfjob distributed-tensorflow-job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check all the pods created by this TFJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distributed-tensorflow-job-ps-0       1/1     Running   0          64s\r\n",
      "distributed-tensorflow-job-worker-0   1/1     Running   0          64s\r\n",
      "distributed-tensorflow-job-worker-1   1/1     Running   0          63s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pod | grep distributed-tensorflow-job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check logs of one worker pod\n",
    "Re-run the following cell periodically to see the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n",
      "  from ._conv import register_converters as _register_converters\r\n",
      "2020-05-09 01:48:40.915473: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n",
      "2020-05-09 01:48:40.934830: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> distributed-tensorflow-job-ps-0.anonymous.svc:2222}\r\n",
      "2020-05-09 01:48:40.935041: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2222, 1 -> distributed-tensorflow-job-worker-1.anonymous.svc:2222}\r\n",
      "2020-05-09 01:48:40.935572: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2222\r\n",
      "WARNING:tensorflow:From /var/tf_dist_mnist/dist_mnist.py:239: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Please switch to tf.train.MonitoredTrainingSession\r\n",
      "2020-05-09 01:48:41.722287: I tensorflow/core/distributed_runtime/master_session.cc:1017] Start master session 1cfcab5e6df9e06c with config: device_filters: \"/job:ps\" device_filters: \"/job:worker/task:0\" allow_soft_placement: true\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs distributed-tensorflow-job-worker-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: \"kubeflow.org/v1\"\r\n",
      "kind: \"PyTorchJob\"\r\n",
      "metadata:\r\n",
      "  name: \"distributed-pytorch-job\"\r\n",
      "spec:\r\n",
      "  pytorchReplicaSpecs:\r\n",
      "    Master:\r\n",
      "      replicas: 1\r\n",
      "      restartPolicy: OnFailure\r\n",
      "      template:\r\n",
      "        metadata:\r\n",
      "          annotations:\r\n",
      "            sidecar.istio.io/inject: \"false\"\r\n",
      "        spec:\r\n",
      "          containers:\r\n",
      "            - name: pytorch\r\n",
      "              image: gcr.io/kubeflow-ci/pytorch-dist-mnist_test:1.0\r\n",
      "              args: [\"--backend\", \"gloo\"]\r\n",
      "              # Comment out the below resources to use the CPU.\r\n",
      "              #resources:\r\n",
      "                #limits:\r\n",
      "                  #nvidia.com/gpu: 1\r\n",
      "    Worker:\r\n",
      "      replicas: 2\r\n",
      "      restartPolicy: OnFailure\r\n",
      "      template:\r\n",
      "        metadata:\r\n",
      "          annotations:\r\n",
      "            sidecar.istio.io/inject: \"false\"\r\n",
      "        spec:\r\n",
      "          containers:\r\n",
      "            - name: pytorch\r\n",
      "              image: gcr.io/kubeflow-ci/pytorch-dist-mnist_test:1.0\r\n",
      "              args: [\"--backend\", \"gloo\"]\r\n",
      "              # Comment out the below resources to use the CPU.\r\n",
      "              #resources:\r\n",
      "                #limits:\r\n",
      "                  #nvidia.com/gpu: 1\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./distributed-training-jobs/distributed-pytorch-job.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorchjob.kubeflow.org/distributed-pytorch-job created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f ./distributed-training-jobs/distributed-pytorch-job.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         distributed-pytorch-job\r\n",
      "Namespace:    anonymous\r\n",
      "Labels:       <none>\r\n",
      "Annotations:  kubectl.kubernetes.io/last-applied-configuration:\r\n",
      "                {\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"distributed-pytorch-job\",\"namespace\":\"anonymous\"}...\r\n",
      "API Version:  kubeflow.org/v1\r\n",
      "Kind:         PyTorchJob\r\n",
      "Metadata:\r\n",
      "  Creation Timestamp:  2020-05-09T01:51:11Z\r\n",
      "  Generation:          1\r\n",
      "  Resource Version:    9510\r\n",
      "  Self Link:           /apis/kubeflow.org/v1/namespaces/anonymous/pytorchjobs/distributed-pytorch-job\r\n",
      "  UID:                 8eec4837-9197-11ea-a820-0242ac110012\r\n",
      "Spec:\r\n",
      "  Pytorch Replica Specs:\r\n",
      "    Master:\r\n",
      "      Replicas:        1\r\n",
      "      Restart Policy:  OnFailure\r\n",
      "      Template:\r\n",
      "        Metadata:\r\n",
      "          Annotations:\r\n",
      "            sidecar.istio.io/inject:  false\r\n",
      "        Spec:\r\n",
      "          Containers:\r\n",
      "            Args:\r\n",
      "              --backend\r\n",
      "              gloo\r\n",
      "            Image:  gcr.io/kubeflow-ci/pytorch-dist-mnist_test:1.0\r\n",
      "            Name:   pytorch\r\n",
      "    Worker:\r\n",
      "      Replicas:        2\r\n",
      "      Restart Policy:  OnFailure\r\n",
      "      Template:\r\n",
      "        Metadata:\r\n",
      "          Annotations:\r\n",
      "            sidecar.istio.io/inject:  false\r\n",
      "        Spec:\r\n",
      "          Containers:\r\n",
      "            Args:\r\n",
      "              --backend\r\n",
      "              gloo\r\n",
      "            Image:  gcr.io/kubeflow-ci/pytorch-dist-mnist_test:1.0\r\n",
      "            Name:   pytorch\r\n",
      "Events:\r\n",
      "  Type    Reason                   Age   From              Message\r\n",
      "  ----    ------                   ----  ----              -------\r\n",
      "  Normal  SuccessfulCreatePod      2s    pytorch-operator  Created pod: distributed-pytorch-job-master-0\r\n",
      "  Normal  SuccessfulCreateService  2s    pytorch-operator  Created service: distributed-pytorch-job-master-0\r\n",
      "  Normal  SuccessfulCreatePod      1s    pytorch-operator  Created pod: distributed-pytorch-job-worker-0\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe pytorchjob distributed-pytorch-job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distributed-pytorch-job-master-0      0/1     ContainerCreating   0          7s\r\n",
      "distributed-pytorch-job-worker-0      0/1     Init:0/1            0          6s\r\n",
      "distributed-pytorch-job-worker-1      0/1     Init:0/1            0          4s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pod | grep distributed-pytorch-job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check logs of one worker pod\n",
    "Re-run the following cell periodically to see the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (BadRequest): container \"pytorch\" in pod \"distributed-pytorch-job-master-0\" is waiting to start: ContainerCreating\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs distributed-pytorch-job-master-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
